{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your friend has opened a new Food Blogging handle on Instagram and wants to get famous. He wants to follow a lot of people so that he can get noticed quickly but it is a tedious task so he asks you to help him. As you have just learned automation using Selenium, you decided to help him by creating an Instagram Bot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver as wb\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import time\n",
    "\n",
    "path='C:/Users/RAHUL/Documents/Web_Scrapping/Insta-Bot-1/chromedriver'\n",
    "driver=wb.Chrome(executable_path=path)\n",
    "driver\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Login to your Instagram Handle\n",
    "            1. Submit with sample username and password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def user_login(u_name,password):\n",
    "    url='https://www.instagram.com/'\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(3)\n",
    "    username=driver.find_element_by_name(name='username')\n",
    "    username.send_keys(u_name)\n",
    "    pswd=driver.find_element_by_name(name='password')\n",
    "    pswd.send_keys(password)\n",
    "    try:\n",
    "        a=driver.find_element_by_class_name('sqdOP  ')\n",
    "        a.submit()\n",
    "        Not_now=driver.find_element_by_class_name('cmbtv')\n",
    "        Not_now.click()\n",
    "        time.sleep(2)\n",
    "        off_notification=driver.find_element_by_class_name('aOOlW.HoLwm')\n",
    "        off_notification.click()\n",
    "    except:\n",
    "        print(\"Please check your entered username or password one of them is incorrect\")\n",
    "    \n",
    "u_name=input()\n",
    "password=input()\n",
    "user_login(u_name,password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Type for “food” in search bar and print all the names of the Instagram Handles that are displayed in list after typing “food”\n",
    "            1. Note : Make sure to avoid printing hashtags\n",
    "            2. Searching and Opening a profile using \n",
    "                2.1 Open profile of “So Delhi”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foodieetraveller_sakshi\n",
      "foodtalkindia\n",
      "dilsefoodie\n",
      "concentrate_on_food\n",
      "food_belly11\n",
      "iamwherefoodis\n",
      "food\n",
      "foodiesdelhite\n",
      "food_gambler\n",
      "food.me.more\n",
      "delhieater\n",
      "indian_food_freak\n",
      "foodinsider\n",
      "delhifoodwalks\n",
      "food_lunatic\n",
      "foodelhi\n",
      "street_food_chandigarh\n",
      "foodiekaurexpeditions\n",
      "dillifoodjunkie\n",
      "kitchensuroor\n",
      "foodveda\n",
      "buzzfeedfood\n",
      "ndtv_food\n",
      "foodieveggie\n",
      "yourfoodlab\n",
      "food_and_makeup_lover\n",
      "indianfood_lovers\n",
      "foodmaniacindia\n",
      "foodbossindia\n",
      "palateofdelhi\n",
      "_foodonaplate_\n",
      "foodisnirvana\n",
      "pune_food_blogger\n",
      "foodconnectindia\n",
      "foodhallindia\n",
      "fityetfoodie\n",
      "delhifoodie\n",
      "foodcastle_by_devika\n",
      "foodiesince96\n",
      "foodinmyplate\n",
      "foodieebites\n",
      "foodyprachi\n",
      "food_travel_etc\n",
      "food_affair\n",
      "foodgastic_amdavadi\n",
      "licious_foods\n",
      "foodjurno\n",
      "food_trail\n",
      "Horn Ok Please - Food Truck Festival\n",
      "alotlike_food\n",
      "food_maple05\n",
      "what.blue.eats\n",
      "foodiefiction1\n",
      "foodmani4c\n"
     ]
    }
   ],
   "source": [
    "def search(value):\n",
    "    srch=driver.find_element_by_class_name('XTCLo ')\n",
    "    srch.send_keys(value)\n",
    "\n",
    "value='food'\n",
    "search(value) # search for Food\n",
    "\n",
    "time.sleep(3)\n",
    "try:\n",
    "    li=driver.find_elements_by_class_name('Ap253')\n",
    "    for i in li:\n",
    "        if i.get_attribute('innerHTML')[0]!='#':\n",
    "            print(i.get_attribute('innerHTML'))\n",
    "except:\n",
    "    print(\"Something went wrong\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Follow/Unfollow given handle - \n",
    "            1. Open the Instagram Handle of “So Delhi”\n",
    "            2. Start following it. Print a message if you are already following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_search():\n",
    "    srch=driver.find_element_by_class_name('XTCLo ')\n",
    "    srch.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "\n",
    "clear_search()\n",
    "profile_name='So Delhi'\n",
    "search(profile_name)\n",
    "\n",
    "time.sleep(2)\n",
    "wait=WebDriverWait(driver,10)\n",
    "profile=wait.until(EC.presence_of_element_located((By.XPATH,'//a[contains(@class,\"yCE8d\")]')))\n",
    "profile.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "try:\n",
    "    driver.find_element_by_xpath('//span[contains(@class,\"vBF20\")]/button/div')\n",
    "    print('Already following')\n",
    "    \n",
    "except NoSuchElementException:\n",
    "    follow=driver.find_element_by_xpath('//span[contains(@class,\"vBF20\")]/button')\n",
    "    follow.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. After following, unfollow the instagram handle. Print a message if you have already unfollowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    opt_unfollow=driver.find_element_by_xpath('//span[contains(@class,\"vBF20\")]/button/div')\n",
    "    opt_unfollow.click()\n",
    "    unfollow=driver.find_element_by_xpath('//button[contains(@class,\"-Cab_\")]')\n",
    "    unfollow.click()\n",
    "    \n",
    "except NoSuchElementException:\n",
    "    print('Already Unfollowed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Like/Unlike posts\n",
    "            1. Liking the top 30 posts of the ‘dilsefoodie'. Print message if you have already liked it.            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post 1 . Already liked\n",
      "Post 2 . Already liked\n",
      "Post 3 . Already liked\n",
      "Post 4 . Already liked\n",
      "Post 5 . Already liked\n",
      "Post 6 . Already liked\n",
      "Post 7 . Already liked\n",
      "Post 8 . Already liked\n",
      "Post 9 . Already liked\n",
      "Post 10 . Already liked\n",
      "Post 11 . Already liked\n",
      "Post 12 . Already liked\n",
      "Post 13 . Already liked\n",
      "Post 14 . Already liked\n",
      "Post 15 . Already liked\n",
      "Post 16 . Already liked\n",
      "Post 17 . Already liked\n",
      "Post 18 . Already liked\n",
      "Post 19 . Already liked\n",
      "Post 20 . Already liked\n",
      "Post 21 . Already liked\n",
      "Post 22 . Already liked\n",
      "Post 23 . Already liked\n",
      "Post 24 . Already liked\n",
      "Post 25 . Already liked\n",
      "Post 26 . Already liked\n",
      "Post 27 . Already liked\n",
      "Post 28 . Already liked\n",
      "Post 29 . Already liked\n",
      "Post 30 . Already liked\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "#perform clear previous search text and searching our text\n",
    "\n",
    "clear_search()\n",
    "profile_name='dilsefoodie'\n",
    "search(profile_name)\n",
    "\n",
    "#waiting for a little to click on the first profile search result \n",
    "wait=WebDriverWait(driver,10)\n",
    "profile=wait.until(EC.presence_of_element_located((By.XPATH,'//a[contains(@class,\"yCE8d\")]')))\n",
    "profile.click()\n",
    "\n",
    "# finding the first post and clicking on it.\n",
    "time.sleep(2)\n",
    "post= driver.find_element_by_class_name('_9AhH0')\n",
    "post.click()\n",
    "\n",
    "#waiting a little so that the post can be open within a popup:\n",
    "time.sleep(3)\n",
    "\n",
    "#finding the heart icon to check whether it is liked or not\n",
    "heart=driver.find_element_by_css_selector('span.fr66n button span svg')\n",
    "h1=heart.get_attribute('innerHTML')\n",
    "\n",
    "count=0\n",
    "#if yes then print \"Already liked\"\n",
    "if '3.1c-4.5' in h1:\n",
    "    count+=1\n",
    "    print(\"Post\",count,'.','Already liked')\n",
    "    \n",
    "#else locating \n",
    "else:\n",
    "#     heart=driver.find_element_by_class_name('fr66n')\n",
    "    heart.click()\n",
    "    \n",
    "# repeating the above actions for next 29 posts:\n",
    "for i in range(29):\n",
    "    # going to next post by clicking on > icon in the popup frame\n",
    "    next_img= driver.find_element_by_xpath(\"//a[contains(@class,'_65Bje  ')]\")\n",
    "    next_img.click()\n",
    "    \n",
    "    #perform wait till in the next popup like button is located\n",
    "    wait=WebDriverWait(driver,10)\n",
    "    like=wait.until(EC.presence_of_element_located((By.CLASS_NAME,\"fr66n\")))\n",
    "\n",
    "    #check if the post is liked or not,\n",
    "    heart=driver.find_element_by_css_selector('span.fr66n button span svg')\n",
    "    h1=heart.get_attribute('innerHTML')\n",
    "    \n",
    "    #if yes then print(Already liked)\n",
    "    if '3.1c-4.5' in h1:\n",
    "        count+=1\n",
    "        print(\"Post\",count,'.','Already liked', )\n",
    "        \n",
    "    #else like the post:\n",
    "    else:\n",
    "        count+=1\n",
    "        like.click()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Unliking the top 30 posts of the ‘dilsefoodie’. Print message if you have already unliked it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post 1 . Already Unliked\n",
      "Post 2 . Already unliked\n",
      "Post 3 . Already unliked\n",
      "Post 4 . Already unliked\n",
      "Post 5 . Already unliked\n",
      "Post 6 . Already unliked\n",
      "Post 7 . Already unliked\n",
      "Post 8 . Already unliked\n",
      "Post 9 . Already unliked\n",
      "Post 10 . Already unliked\n",
      "Post 11 . Already unliked\n",
      "Post 12 . Already unliked\n",
      "Post 13 . Already unliked\n",
      "Post 14 . Already unliked\n",
      "Post 15 . Already unliked\n",
      "Post 16 . Already unliked\n",
      "Post 17 . Already unliked\n",
      "Post 18 . Already unliked\n",
      "Post 19 . Already unliked\n",
      "Post 20 . Already unliked\n",
      "Post 21 . Already unliked\n",
      "Post 22 . Already unliked\n",
      "Post 23 . Already unliked\n",
      "Post 24 . Already unliked\n",
      "Post 25 . Already unliked\n",
      "Post 26 . Already unliked\n",
      "Post 27 . Already unliked\n",
      "Post 28 . Already unliked\n",
      "Post 29 . Already unliked\n",
      "Post 30 . Already unliked\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "driver.back()\n",
    "time.sleep(3)\n",
    "#searching for the profile\n",
    "clear_search()\n",
    "profile_name='dilsefoodie'\n",
    "search(profile_name)\n",
    "\n",
    "#going to profile by clicking on the first handle in the search dropdown\n",
    "wait=WebDriverWait(driver,10)\n",
    "profile=wait.until(EC.presence_of_element_located((By.XPATH,'//a[contains(@class,\"yCE8d\")]')))\n",
    "profile.click()\n",
    " \n",
    "\n",
    "#clicking on the first post in the profile\n",
    "post=driver.find_element_by_class_name('_9AhH0')\n",
    "time.sleep(2)\n",
    "post.click()\n",
    "\n",
    "count=0\n",
    "\n",
    "#checking whether the post is liked or not  \n",
    "heart=driver.find_element_by_css_selector('span.fr66n button span svg')\n",
    "h1=heart.get_attribute('innerHTML')\n",
    "\n",
    "#if liked then unlike it\n",
    "if '3.1c-4.5' in h1:\n",
    "    heart.click()\n",
    "    \n",
    "#else print \"Already unliked\"\n",
    "else:\n",
    "    count+=1\n",
    "    print(\"Post\",count,'.',\"Already Unliked\")\n",
    "    \n",
    "# perofrming above operation again for next 29 posts:\n",
    "for i in range(29):\n",
    "    #goint to next post by clicking on the > icon in popup frame\n",
    "    next_post=driver.find_element_by_xpath('//a[contains(@class,\"_65Bje  \")]')\n",
    "#     time.sleep(1)\n",
    "    next_post.click()\n",
    "    \n",
    "    #wait till in the next popup like button is located \n",
    "    wait=WebDriverWait(driver,10)\n",
    "    dislike=wait.until(EC.presence_of_element_located((By.CLASS_NAME,\"fr66n\")))\n",
    "    \n",
    "    # finding the like button and check it whether it is liked or not\n",
    "    heart=driver.find_element_by_css_selector('span.fr66n button svg')\n",
    "    h1=heart.get_attribute('innerHTML')\n",
    "    \n",
    "    #if liked then click again to unlike:\n",
    "    if '3.1c-4.5' in h1:\n",
    "        count+=1\n",
    "        dislike.click()\n",
    "    \n",
    "    #else print \"Already unliked\"\n",
    "    else:\n",
    "        count+=1\n",
    "        print(\"Post\",count,\".\",\"Already unliked\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extract list of followers\n",
    "            1. Extract the usernames of the first 500 followers of ‘foodtalkindia’ and ‘sodelhi’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . sunflowerwhowrites\n",
      "2 . shakib90088\n",
      "3 . iam_rooben\n",
      "4 . ggndp84a\n",
      "5 . garima10ag\n",
      "6 . sochnewali.baat\n",
      "7 . isthishimanshu\n",
      "8 . pawan__shakti\n",
      "9 . nehanaaz496\n",
      "10 . arpita_g23\n",
      "11 . undekhadelhi\n",
      "12 . areionevents\n",
      "13 . tanyasehgal16\n",
      "14 . gr_wanders\n",
      "15 . dudeeirdk\n",
      "16 . bakchodhii\n",
      "17 . ravindran_varsha\n",
      "18 . shivam____panchal\n",
      "19 . riyagoyal_24\n",
      "20 . engela.saha\n",
      "21 . srivatsachetan\n",
      "22 . jeevesh_sahni58\n",
      "23 . nimrat_thakur\n",
      "24 . amitparadise\n",
      "25 . blogger_by__chance\n",
      "26 . lockd_ownartist\n",
      "27 . bhupeshmathur\n",
      "28 . ritika_verma06\n",
      "29 . vibha.pandey\n",
      "30 . garumenghwani\n",
      "31 . cabezapedropablo\n",
      "32 . jakhar2513\n",
      "33 . xpvtlmt\n",
      "34 . umema.pvt_\n",
      "35 . chaai__i\n",
      "36 . otmanebenhanini\n",
      "37 . eat.read.design\n",
      "38 . gainful_am\n",
      "39 . mhkmaheshwari09\n",
      "40 . suprita.sh21\n",
      "41 . gorkalarisa\n",
      "42 . iamqueen3000\n",
      "43 . roopalisharma10\n",
      "44 . chandrikaright\n",
      "45 . food_staan\n",
      "46 . kirtik1212\n",
      "47 . anjali_choudhary001\n",
      "48 . nasirai123knd\n",
      "49 . dmsfromyourex\n",
      "50 . _aashish25\n",
      "51 . bansalshalu88\n",
      "52 . akshaymishra524\n",
      "53 . nids_mi_sa_va\n",
      "54 . vikaspariharpindari\n",
      "55 . samikshya._.singh97\n",
      "56 . makeupstoriesbyshwetanjali\n",
      "57 . devender_tech\n",
      "58 . mohnasharma_\n",
      "59 . mahima_massey9\n",
      "60 . coohmasks\n",
      "61 . arpit5gupta\n",
      "62 . archhieee_007\n",
      "63 . luthra_0296\n",
      "64 . rishabh__saxena_\n",
      "65 . goyalmona293\n",
      "66 . shabaj1998\n",
      "67 . livefree_30\n",
      "68 . worldon_lens\n",
      "69 . carolyniieeee\n",
      "70 . avibhasin2\n",
      "71 . sagrika_agg\n",
      "72 . ayuzhzeth\n",
      "73 . makeovers_by_nidhirawat\n",
      "74 . gorav_narang\n",
      "75 . divyanshidm\n",
      "76 . bong_discover\n",
      "77 . manprabh.07\n",
      "78 . saimafayyaz04\n",
      "79 . nehasachdeva12dec\n",
      "80 . pahadi.beautyyyy\n",
      "81 . prashant_9215\n",
      "82 . vaibhavshaw17\n",
      "83 . shivaninewincity\n",
      "84 . viaandiamondemporio\n",
      "85 . secluded_nomad\n",
      "86 . imneerja\n",
      "87 . kanika.narula.180\n",
      "88 . justswetam\n",
      "89 . justrealthingss\n",
      "90 . bagwariayush\n",
      "91 . cosmoverses\n",
      "92 . devyani_21\n",
      "93 . richa.1602\n",
      "94 . dakshagarwal_\n",
      "95 . somu_blush\n",
      "96 . himanshi_dahiya22\n",
      "97 . _pankajrao\n",
      "98 . sanyakher\n",
      "99 . just_flip_ur_coin\n",
      "100 . offical.ak.47\n",
      "101 . nikk_like\n",
      "102 . kashifah3264\n",
      "103 . khushboo_patni\n",
      "104 . s.u.n.s.h.i.n.e_96\n",
      "105 . neet_chahal13\n",
      "106 . esharghhh_\n",
      "107 . er._oligarch\n",
      "108 . yourhealthydietplanner\n",
      "109 . vinceampersand\n",
      "110 . nikitaskingdom\n",
      "111 . dheerajyadav_9\n",
      "112 . shambhavi2903\n",
      "113 . foodie_crush26\n",
      "114 . ichbin_nameless\n",
      "115 . iritikachauhan\n",
      "116 . thearyanshekhawat\n",
      "117 . bhumani.tyagi\n",
      "118 . sandy_vegfoods\n",
      "119 . tk.pvtt\n",
      "120 . rimpsss75\n",
      "121 . rajatbhallaofficial\n",
      "122 . shivanidz25\n",
      "123 . ishu.1252\n",
      "124 . ___priyanshi.__\n",
      "125 . stephen.michael.50309277\n",
      "126 . rawat.travels\n",
      "127 . from_my_glasses\n",
      "128 . dansishanshari\n",
      "129 . ayushimk\n",
      "130 . that.alive.soul\n",
      "131 . flightaides\n",
      "132 . chetan13467sharma\n",
      "133 . ishmeetsinghsethi\n",
      "134 . _andreaanand_\n",
      "135 . naimnawabkanpur\n",
      "136 . __shraddha____\n",
      "137 . jagvi_arora\n",
      "138 . _sakshibisht\n",
      "139 . abulladk\n",
      "140 . manju773\n",
      "141 . sonaakshi.chaudhary\n",
      "142 . mishraww_alok\n",
      "143 . drkajalmugraiofficial\n",
      "144 . y_prashant10\n",
      "145 . karanvashisth24\n",
      "146 . whatgoesinmytummy\n",
      "147 . amitrathore9810\n",
      "148 . foodietude03\n",
      "149 . me.mekha\n",
      "150 . manu_singh95\n",
      "151 . kanika_kataria17\n",
      "152 . sachinhooda\n",
      "153 . cutepixel________\n",
      "154 . exquisite_depiction\n",
      "155 . nirmalathiyam\n",
      "156 . abhishekjangid971\n",
      "157 . surbhi_saraswat\n",
      "158 . richachawla9\n",
      "159 . whosidnautiyal\n",
      "160 . tripathi.vibha\n",
      "161 . srayer16\n",
      "162 . _photo.nat\n",
      "163 . xx.logophile.xx\n",
      "164 . sonalitripathy\n",
      "165 . safetyproducts0503\n",
      "166 . gastronome101\n",
      "167 . ramen.budget\n",
      "168 . anshika_2209_\n",
      "169 . aanand_gec007\n",
      "170 . _.riyaa.__\n",
      "171 . aditi_gahlawat\n",
      "172 . ruhaani_khayalat\n",
      "173 . officialshubham2002\n",
      "174 . chuaungo.zuali\n",
      "175 . choudhary_niti123\n",
      "176 . sagar1092\n",
      "177 . techie_mukesh\n",
      "178 . ayeman01\n",
      "179 . p_ranav16\n",
      "180 . _i_m_syed_\n",
      "181 . lerazaliubovskaia\n",
      "182 . iamshauryakundra3924\n",
      "183 . this.is.me.nope\n",
      "184 . multiservicesent\n",
      "185 . rosshitverma2456\n",
      "186 . nilimakumar_2007\n",
      "187 . dodotravels\n",
      "188 . riya.sapraa30\n",
      "189 . deep_shahkot_\n",
      "190 . rahul_saras\n",
      "191 . _urvashi.chaudhary\n",
      "192 . _kumkummm\n",
      "193 . imbharatdhingra\n",
      "194 . dev.editography\n",
      "195 . monag1508\n",
      "196 . robinnchoudhary\n",
      "197 . srishti.sharma012\n",
      "198 . ansh.kanojia.9\n",
      "199 . adity.a6370\n",
      "200 . drummer_sj\n",
      "201 . sakina_1sh\n",
      "202 . tannu_sharma26\n",
      "203 . kanishq_basoya_dellhii0001\n",
      "204 . richa_kasana\n",
      "205 . imayushiii\n",
      "206 . swatichauhan664\n",
      "207 . simran_digwal\n",
      "208 . nehabafna10\n",
      "209 . shahmeer7147\n",
      "210 . manojpandorm\n",
      "211 . sayanbera5\n",
      "212 . __its_ur_girl___\n",
      "213 . dishuxx._\n",
      "214 . vishalpayal2219\n",
      "215 . foodgamblers\n",
      "216 . khushii_aroraaa\n",
      "217 . vedika_mehra2\n",
      "218 . simransodhi13\n",
      "219 . artist_of_artz\n",
      "220 . sinnushaw\n",
      "221 . varunsingh909\n",
      "222 . aliakbari083\n",
      "223 . sojaipur\n",
      "224 . aashish_av\n",
      "225 . richa_khandelwal_\n",
      "226 . __brave.soul\n",
      "227 . naina.ruhela.984\n",
      "228 . achelon_21\n",
      "229 . aman__malik\n",
      "230 . vashist_ravi23\n",
      "231 . _saurav_dabas\n",
      "232 . abhishek__trivedi\n",
      "233 . manyakaur_0111\n",
      "234 . mrs.motivationofficial\n",
      "235 . _sheena.bhatia_\n",
      "236 . k_khurana\n",
      "237 . iam_ankurgupta\n",
      "238 . _gauridutta_\n",
      "239 . iamvijaytadalai\n",
      "240 . mmalik83\n",
      "241 . food_on_the_roll\n",
      "242 . oshinjuan\n",
      "243 . spectrexnassa\n",
      "244 . meena_miglani\n",
      "245 . bhawana.tiwari\n",
      "246 . motivation_man_to_man\n",
      "247 . thuptanyma11\n",
      "248 . asdelhi995\n",
      "249 . _sagar_singh_05\n",
      "250 . riya.sharma45\n",
      "251 . makeupbyrasheeka\n",
      "252 . rishamohan\n",
      "253 . harshayyyy_\n",
      "254 . euphonywithinus\n",
      "255 . amritaraj13\n",
      "256 . madaandeeksha\n",
      "257 . jr.akaash14\n",
      "258 . baggaavnikaur\n",
      "259 . _anushka_00004\n",
      "260 . ak_rockss\n",
      "261 . ritudhull\n",
      "262 . kumarmausam_24\n",
      "263 . ttheacaiguy\n",
      "264 . saajan2254\n",
      "265 . arindam_kashyapp\n",
      "266 . avid_ayush\n",
      "267 . wow_clickz\n",
      "268 . kishu_garud\n",
      "269 . mr.pogo.boi.nani\n",
      "270 . sethi.khushboo\n",
      "271 . belloshri\n",
      "272 . diks__077\n",
      "273 . brick_byy_brick\n",
      "274 . xx___0_r_i_t_e_s_h_0___xx\n",
      "275 . ionlyfollowuglyhumans\n",
      "276 . zor.js\n",
      "277 . cocomelondiaries\n",
      "278 . amitsingh17011996\n",
      "279 . shipra_malik18\n",
      "280 . zarafshan_zohair1\n",
      "281 . ishortstuff\n",
      "282 . _shab_parast\n",
      "283 . _twinklesharma._\n",
      "284 . rawatlover8800\n",
      "285 . bake_a_wish_delhi\n",
      "286 . samriddhi_srijan\n",
      "287 . __nikki96__\n",
      "288 . mahima_chauhann\n",
      "289 . foodielife1010\n",
      "290 . vishu.vaishali20\n",
      "291 . simrit.chadha_\n",
      "292 . sketch.consultancy\n",
      "293 . the_hijabi_eats\n",
      "294 . keepit_simple.co\n",
      "295 . theabhinavjanu\n",
      "296 . _divyatrivedi\n",
      "297 . anshumanpuwar\n",
      "298 . rajninarender\n",
      "299 . shwetapatnii\n",
      "300 . aarushii777\n",
      "301 . foodie__paradise__\n",
      "302 . __theblogger_\n",
      "303 . _niti_._\n",
      "304 . akash_hada\n",
      "305 . anmxoxo_\n",
      "306 . _nishirawat15\n",
      "307 . neharichhariyarichhariya\n",
      "308 . nounoublns\n",
      "309 . the_hodophile_girll\n",
      "310 . foo_dforsoul\n",
      "311 . sanyukta_00_6\n",
      "312 . bharti_2k\n",
      "313 . de.va524\n",
      "314 . agarwal_nandini__\n",
      "315 . so.ludhiana\n",
      "316 . parveengehl\n",
      "317 . vedikaanviangels\n",
      "318 . aayushipruthii\n",
      "319 . phtonicoder\n",
      "320 . lofipig\n",
      "321 . bhutani_ajay\n",
      "322 . tejveer_sa\n",
      "323 . someone__finallyyy\n",
      "324 . vpsaliha\n",
      "325 . simpy_yadav_27\n",
      "326 . mittalpatel35380\n",
      "327 . satvik2252\n",
      "328 . saqibhashmi97\n",
      "329 . mileee08\n",
      "330 . indian.cuisine9\n",
      "331 . ishi.phishi\n",
      "332 . kajalkajal843\n",
      "333 . monishgaury\n",
      "334 . bwarsha\n",
      "335 . nikhil.1425_\n",
      "336 . itsaniee_15\n",
      "337 . gandhidhaarna\n",
      "338 . tahi.r1418\n",
      "339 . r.hassaram\n",
      "340 . iamsajidbaksh\n",
      "341 . verytoxicwriter\n",
      "342 . ____anshikagupta____\n",
      "343 . shweta.2599\n",
      "344 . karanjaat008\n",
      "345 . jiyaroy499\n",
      "346 . the.inspiring.foodie\n",
      "347 . narang_queen\n",
      "348 . himanshubeirwa1\n",
      "349 . ramneek.k_chawla\n",
      "350 . cheena_arora\n",
      "351 . sammridhi_14\n",
      "352 . _thegirlwithstars\n",
      "353 . anniee30_90\n",
      "354 . resolute_silienteyes\n",
      "355 . bhavishyasworld\n",
      "356 . _nikhita_m\n",
      "357 . fara.sid\n",
      "358 . ishitayadav9\n",
      "359 . shitizz_z\n",
      "360 . kachauri_gali\n",
      "361 . a_d_vaswani\n",
      "362 . _ambitious_kreations_\n",
      "363 . gujratigarbaking\n",
      "364 . sanyavashisth\n",
      "365 . kaur_jaswinder_13\n",
      "366 . ishankagg\n",
      "367 . kajal.piwal\n",
      "368 . _anni_2917\n",
      "369 . umesh_sagar.333\n",
      "370 . shivanisanklp\n",
      "371 . kabir_1.11\n",
      "372 . pih1909\n",
      "373 . jd_mehra96\n",
      "374 . __.srishtiiii_\n",
      "375 . chippdnails\n",
      "376 . elsa.is.rare\n",
      "377 . crazy_as_lol\n",
      "378 . indresh_meena\n",
      "379 . singla4007\n",
      "380 . raman_200187\n",
      "381 . oyesandeep\n",
      "382 . secondsight1710\n",
      "383 . tanujgupta0405\n",
      "384 . vaibhavhere1\n",
      "385 . ta.nvi9412\n",
      "386 . shinebellaofficial\n",
      "387 . na.zim8224\n",
      "388 . avasthi.akash\n",
      "389 . nitesh_hr_51\n",
      "390 . saurabhm606\n",
      "391 . harshkatiyar2000\n",
      "392 . jasoliya23\n",
      "393 . goodiesalley_returngiftstore\n",
      "394 . temur_otajanov96\n",
      "395 . purpledrops_\n",
      "396 . akansha_2806\n",
      "397 . abiii_prjaptiii\n",
      "398 . _just.goddessin_\n",
      "399 . insane_heart12\n",
      "400 . diivii0204\n",
      "401 . callboy7831\n",
      "402 . food_itionary\n",
      "403 . vermasanya\n",
      "404 . bharatluthra36\n",
      "405 . nkd_1987\n",
      "406 . sonamwonders\n",
      "407 . tale_of_yummm\n",
      "408 . lavanya_giri_\n",
      "409 . ashwiniii_k\n",
      "410 . isparklessence\n",
      "411 . logicallyblind\n",
      "412 . delhi_climbs\n",
      "413 . mr_jayubha_darbar_\n",
      "414 . anky.gautam2010\n",
      "415 . mguptaa3\n",
      "416 . crispy.agraaaa\n",
      "417 . diveshagarwall\n",
      "418 . frenchfriespvtltd\n",
      "419 . _rao_gaurav_yadav_\n",
      "420 . lordsnow_of_north\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421 . sad.gayboi\n",
      "422 . anshumanunplugged\n",
      "423 . chandniimalik\n",
      "424 . polishnailbar.in\n",
      "425 . ashishra89\n",
      "426 . agnihotjai\n",
      "427 . livingsmita\n",
      "428 . alpsjain27\n",
      "429 . indubordoloi\n",
      "430 . my_travel_india\n",
      "431 . famishedthoughts\n",
      "432 . child_of90s\n",
      "433 . ronakagarwal40\n",
      "434 . iamrohitsharma\n",
      "435 . shopcitydelhi\n",
      "436 . me_shikhar.14\n",
      "437 . green_heaven_delhi\n",
      "438 . shanan.sf\n",
      "439 . balveer7962\n",
      "440 . _bhardwaj.14\n",
      "441 . kenym_prtin\n",
      "442 . sejal_bajaj28\n",
      "443 . gautamkaran18\n",
      "444 . _aks.m_\n",
      "445 . shiv.bhatia2204\n",
      "446 . sagar13._\n",
      "447 . manish_fouji\n",
      "448 . aadi_jain_anchal_jain\n",
      "449 . alishasinghaniya78\n",
      "450 . ashutoshsgh\n",
      "451 . ekbholenath\n",
      "452 . hungry_bird22\n",
      "453 . shwetagoel8898\n",
      "454 . mashkurraza\n",
      "455 . parjapatiavdhesh\n",
      "456 . bulleter_\n",
      "457 . _bhumi_writes_\n",
      "458 . namnishkaur\n",
      "459 . sonalipatel3474\n",
      "460 . tisha_ydv\n",
      "461 . pulkitsaxenaa\n",
      "462 . dilli.com_\n",
      "463 . tmsquotes2all\n",
      "464 . bawaal_zindagi\n",
      "465 . _vrindabajaj_\n",
      "466 . successfulsoftware\n",
      "467 . misstylebound\n",
      "468 . tanishaakaranwal\n",
      "469 . blend_of_quotes\n",
      "470 . glowingdreamzzz\n",
      "471 . dil_bole_khana\n",
      "472 . mdmushahidashraf\n",
      "473 . bellenadiviza\n",
      "474 . manika_dhiman\n",
      "475 . ayurvedicsunny\n",
      "476 . gubgibme\n",
      "477 . rahul.1236477\n",
      "478 . g.poojah\n",
      "479 . pmp_delights\n",
      "480 . arya_value_bazaar\n",
      "481 . urstrulysudhanshu\n",
      "482 . mr.mnv_05\n",
      "483 . akashishkumar22\n",
      "484 . jiyoraw.cold.pressed.oil\n",
      "485 . whatasnap\n",
      "486 . eshmeett_kaur\n",
      "487 . swarnima.singh_01\n",
      "488 . mr_sanu_0017\n",
      "489 . zindahuyaarrr\n",
      "490 . hardikknaik\n",
      "491 . sarnaaarti\n",
      "492 . dikshiita\n",
      "493 . aayush___\n",
      "494 . vineetneo\n",
      "495 . rahulwedsrupal\n",
      "496 . prime_keeda\n",
      "497 . aarushi11\n",
      "498 . chitramohan.7\n",
      "499 . asya_by_ambika\n",
      "500 . ydvvaibhav\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "driver.back()\n",
    "time.sleep(3)\n",
    "#clear search textBox and search for the profile name\n",
    "clear_search()\n",
    "profile_name='sodelhi'\n",
    "search(profile_name)\n",
    "\n",
    "#wait till the all data loads in the search dropdown then click on the first result\n",
    "wait=WebDriverWait(driver,5)\n",
    "profile=wait.until(EC.presence_of_element_located((By.XPATH,'//a[contains(@class,\"yCE8d  \")]')))\n",
    "profile.click()\n",
    "\n",
    "\n",
    "time.sleep(1)\n",
    "followers=driver.find_element_by_partial_link_text('followers')\n",
    "followers.click()\n",
    "\n",
    "#scroll down to expand the list\n",
    "results=driver.find_element_by_class_name('isgrP')\n",
    "\n",
    "for i in range(50):\n",
    "    time.sleep(1)\n",
    "    driver.execute_script(\"arguments[0].scrollTop=arguments[0].scrollHeight\",results)\n",
    "    \n",
    "followers_list=driver.find_elements_by_xpath(\"//a[contains(@class,'FPmhX ')]\")\n",
    "\n",
    "count=1\n",
    "for i in followers_list:\n",
    "    print(count,'.',i.get_attribute('innerHTML'))\n",
    "    count+=1\n",
    "    if count==501:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . flatterdofficial\n",
      "2 . abhi696\n",
      "3 . omkarpawar8565\n",
      "4 . casually_controversial\n",
      "5 . thevillagemeal\n",
      "6 . lprutha\n",
      "7 . sa.na_28\n",
      "8 . thefoodiesista\n",
      "9 . shahbazansari9820\n",
      "10 . hot.on.kos.heels\n",
      "11 . jusstdoodling\n",
      "12 . irishcoffee_01\n",
      "13 . podarvarun\n",
      "14 . barbie___world___\n",
      "15 . khajarayeesahmed\n",
      "16 . shayaneducationalhub\n",
      "17 . _.murar._\n",
      "18 . _anzika\n",
      "19 . vivek_chikate\n",
      "20 . nneeta.y\n",
      "21 . the_hogging_trio_\n",
      "22 . rituagarwal4374\n",
      "23 . iamsyedalirizvi\n",
      "24 . royrahul_91\n",
      "25 . theelegantfemme\n",
      "26 . rubinamemon85\n",
      "27 . rajat__160\n",
      "28 . manish00029\n",
      "29 . munot.rashmi\n",
      "30 . createcultivatejoy\n",
      "31 . gandhi.smriti\n",
      "32 . moni0505_\n",
      "33 . shivi4611\n",
      "34 . ornagals6\n",
      "35 . dajugia81\n",
      "36 . its_venupriyanka\n",
      "37 . kishorebeniwal\n",
      "38 . bihardesidhaba\n",
      "39 . zarin4573\n",
      "40 . chulhadelight\n",
      "41 . princeyash1980\n",
      "42 . food_please2\n",
      "43 . pareshkvaishya\n",
      "44 . glowiner1\n",
      "45 . zac._.ery\n",
      "46 . chefandreamura\n",
      "47 . zoykhan4057\n",
      "48 . foodiekomal\n",
      "49 . _jjjiiiggaaa_\n",
      "50 . flightaides\n",
      "51 . a.little.pixelated\n",
      "52 . mr__malik__09\n",
      "53 . narmadhaganesh\n",
      "54 . luap123456\n",
      "55 . sarthak_0333\n",
      "56 . nv_sandhu_5911\n",
      "57 . vaidehibabar\n",
      "58 . anubhavpanda\n",
      "59 . me.mekha\n",
      "60 . aditi_gahlawat\n",
      "61 . chetanjangid31\n",
      "62 . shilpi.everyday.bites\n",
      "63 . aditya_khemani\n",
      "64 . auntyspavbhaji\n",
      "65 . divyauttarkar\n",
      "66 . ruhaani_khayalat\n",
      "67 . _officalvicky\n",
      "68 . shine_of_glory_29\n",
      "69 . ranveerr009876\n",
      "70 . idk_whats_for_dinner\n",
      "71 . kawaljeet958\n",
      "72 . surrendering.sunshine\n",
      "73 . crazygal_leo\n",
      "74 . priya_thodduraju\n",
      "75 . sadhanasalunkhe6666\n",
      "76 . rehan__ahmd_\n",
      "77 . bhavin.rj\n",
      "78 . sourabhsippy\n",
      "79 . kashyap_37\n",
      "80 . adity.a6370\n",
      "81 . _spicesindia\n",
      "82 . _neha_singh_20\n",
      "83 . abakescape\n",
      "84 . raunaq.sahni135\n",
      "85 . tipsy_monk\n",
      "86 . themallubong_cooks\n",
      "87 . therealmoizsabri\n",
      "88 . eiijjjuuandsutar\n",
      "89 . madhu_1628\n",
      "90 . mano_bakes\n",
      "91 . sanjaypatil511\n",
      "92 . bohraritu3\n",
      "93 . simul_02\n",
      "94 . leondeny70\n",
      "95 . aswanicaterersevent\n",
      "96 . _.thecakecorner_\n",
      "97 . basirshaikh70\n",
      "98 . foodie_sadrita\n",
      "99 . tasty.jugaad\n",
      "100 . karangupta0320\n",
      "101 . lucknowitiffin\n",
      "102 . foodgamblers\n",
      "103 . anuhoney555\n",
      "104 . _viralfoodz\n",
      "105 . drkajalmugraiofficial\n",
      "106 . chef_gm_\n",
      "107 . subhusbutterhalf\n",
      "108 . nutsnspreads\n",
      "109 . taruna1020\n",
      "110 . marinating_delicacies\n",
      "111 . jassie_punia\n",
      "112 . amit.kashyap9678\n",
      "113 . anuseeksfood\n",
      "114 . kailashkumavat15\n",
      "115 . ttheacaiguy\n",
      "116 . aman_kochar.ak\n",
      "117 . daily.fooddose\n",
      "118 . anshitajain\n",
      "119 . akash.behatre\n",
      "120 . ratndeep_infinitum_advertising\n",
      "121 . kitchen_accessories__1\n",
      "122 . jenashushi\n",
      "123 . kevinphilip___\n",
      "124 . foo_dforsoul\n",
      "125 . princessreemu\n",
      "126 . h.marysupritha\n",
      "127 . addi7853\n",
      "128 . foodpics_shahar\n",
      "129 . affiliate_samir\n",
      "130 . vedikaanviangels\n",
      "131 . phtonicoder\n",
      "132 . _ashish_4911\n",
      "133 . mgquamar\n",
      "134 . mr_construction_interior\n",
      "135 . vikramdilipchavan\n",
      "136 . tahmina.yeasmin.7315\n",
      "137 . parvinder2179\n",
      "138 . baanis.lil.bakery\n",
      "139 . anita_israni\n",
      "140 . _simpleflavour_\n",
      "141 . praveen_victor\n",
      "142 . mr__arbaz__008\n",
      "143 . hellobeecreative2020\n",
      "144 . oblique_travel\n",
      "145 . rupali_rasoii\n",
      "146 . theladyfinger95\n",
      "147 . countrysidegardenr\n",
      "148 . sarojkhemani\n",
      "149 . food_clan_baby\n",
      "150 . emeraldraysolutions\n",
      "151 . minaromany642\n",
      "152 . ditichintaanmehtaa\n",
      "153 . info.samosaz\n",
      "154 . _thehungerstation_\n",
      "155 . hyder9089\n",
      "156 . food_snap_kitchen\n",
      "157 . dakshitakapoor\n",
      "158 . thetrippingfolks\n",
      "159 . faijju_001\n",
      "160 . flavoursofmess\n",
      "161 . __prk_official__\n",
      "162 . tale_of_yummm\n",
      "163 . chakh_kar_dekho\n",
      "164 . pratikchauhan21\n",
      "165 . mr_zahid_khanzk_\n",
      "166 . sad.gayboi\n",
      "167 . letswhiplove\n",
      "168 . foodstylingbypb\n",
      "169 . neriinn\n",
      "170 . pravallika_chandolu\n",
      "171 . _.priii._74\n",
      "172 . preetigoel74\n",
      "173 . __.honeyyyyy._\n",
      "174 . themysterybun\n",
      "175 . ankannandi\n",
      "176 . iamajaykumarvaghela\n",
      "177 . shopcitydelhi\n",
      "178 . silk_attire\n",
      "179 . homeolicious\n",
      "180 . amway___digital_india\n",
      "181 . manniworld.in\n",
      "182 . kingmyfather\n",
      "183 . im.ajay__67\n",
      "184 . sushant.wants.justice\n",
      "185 . bai_g_oni_\n",
      "186 . _ronitp8\n",
      "187 . adityayadavsemri\n",
      "188 . satyenrohra\n",
      "189 . shailviyadav051\n",
      "190 . preetham_ramanaraya\n",
      "191 . mdmushahidashraf\n",
      "192 . poonam_salian\n",
      "193 . foodie.forever__\n",
      "194 . killerbeg\n",
      "195 . young__chow\n",
      "196 . in.the.name.of_food\n",
      "197 . creat_eve_\n",
      "198 . innocent_shudhanshu_thakur_\n",
      "199 . r_j_model.editor\n",
      "200 . pmp_delights\n",
      "201 . blackof.black\n",
      "202 . refectionsthejuicebar\n",
      "203 . ramnanimonica\n",
      "204 . rakesh_desai13\n",
      "205 . vanshajvyas\n",
      "206 . v.for.vikas9\n",
      "207 . 01.991894574\n",
      "208 . snehavachhaney\n",
      "209 . mr_sanu_0017\n",
      "210 . its_shubsbahiram\n",
      "211 . yatendra_charan\n",
      "212 . thebhupendra_\n",
      "213 . n.i.k.h.i.l.y.e.l.e\n",
      "214 . luvnnit\n",
      "215 . great_guneet\n",
      "216 . vikashjha1941\n",
      "217 . businessneur_diet\n",
      "218 . food_vibes27\n",
      "219 . jjeetuu_\n",
      "220 . vikramdhillon751\n",
      "221 . mr_kishan_seth\n",
      "222 . idont2350\n",
      "223 . the_peace_pacer_\n",
      "224 . sadhurice\n",
      "225 . iamprincechandel\n",
      "226 . food.ieforever21\n",
      "227 . dinesh_panther_oo7\n",
      "228 . sofi_gourmet20\n",
      "229 . chai_0_holic\n",
      "230 . sinhaacharya\n",
      "231 . mii_tube_\n",
      "232 . sugarrush_by_simonedsouza\n",
      "233 . shrinidhivijayan\n",
      "234 . wipizzfeed\n",
      "235 . iamishaanssrf\n",
      "236 . veer_ji_malai_chaap_wale_\n",
      "237 . biintkhalifa\n",
      "238 . aditti_patil\n",
      "239 . s.h.u.b.h9\n",
      "240 . ad_astra1997\n",
      "241 . billsucket\n",
      "242 . rotz.rohit\n",
      "243 . rushtoviraj\n",
      "244 . myy.miniworld\n",
      "245 . cute_arru988\n",
      "246 . chatpatichotoriladki\n",
      "247 . in.bonappetit\n",
      "248 . ovalsacha3\n",
      "249 . bithikas_kitchentour\n",
      "250 . samruddhi_2107\n",
      "251 . agirlgottaeat2\n",
      "252 . thefoodabode\n",
      "253 . 4ivr.e\n",
      "254 . djcj516\n",
      "255 . singh.harjesh\n",
      "256 . zafarazizi54\n",
      "257 . nishiuttam\n",
      "258 . thetotos7\n",
      "259 . abhijeetk18\n",
      "260 . mrsultan966\n",
      "261 . sunitaskitchen366\n",
      "262 . deepaktiwari2712\n",
      "263 . farhadfarhad920\n",
      "264 . sushant_.arora\n",
      "265 . slice_of_revel\n",
      "266 . bijaspur_rahul\n",
      "267 . tbcraz\n",
      "268 . _shah_shaival\n",
      "269 . prakyz\n",
      "270 . ra_fun_\n",
      "271 . isha_._vamja_\n",
      "272 . quarantine_homecookingg\n",
      "273 . kirankk1986\n",
      "274 . tisha_lalwani\n",
      "275 . the.fat.table\n",
      "276 . koolisakki\n",
      "277 . aayushmabyrapaneni\n",
      "278 . boxdesignco\n",
      "279 . boyonapex\n",
      "280 . jhakaas_taste\n",
      "281 . uddita.gupta\n",
      "282 . rockingnandinii\n",
      "283 . alekhya.07\n",
      "284 . lee_menon\n",
      "285 . thehumancroissant\n",
      "286 . choice_is_yourz\n",
      "287 . sinfultreats2013\n",
      "288 . sg5482\n",
      "289 . perfectmemerr\n",
      "290 . closet_quorum\n",
      "291 . sreeja_koduru\n",
      "292 . harshalpshah\n",
      "293 . dharani_kathi\n",
      "294 . northdilliwala\n",
      "295 . yashgovil\n",
      "296 . theonethatarrivedlate\n",
      "297 . pv_styles\n",
      "298 . your_scrolling_stopper\n",
      "299 . keerthanasekar_1\n",
      "300 . rakeshmalviya16\n",
      "301 . filmstarsnewschannel\n",
      "302 . contempocooking\n",
      "303 . flavouryourtongue\n",
      "304 . dramstraightcollective\n",
      "305 . cui.sin.e\n",
      "306 . justanothergourmand\n",
      "307 . priyankabidwe\n",
      "308 . ranjita_tgw\n",
      "309 . foo_die_forever\n",
      "310 . hungrybros.official\n",
      "311 . anjalirai812\n",
      "312 . food.drinklover\n",
      "313 . rkstud.hq.guruji\n",
      "314 . storehojai\n",
      "315 . akri9\n",
      "316 . tracktax_consultant\n",
      "317 . kheyaliashar\n",
      "318 . gouriscookbook\n",
      "319 . asolomonlok\n",
      "320 . elina.mohanty\n",
      "321 . prasaddhananjai\n",
      "322 . mund_seewani\n",
      "323 . saraphin_augustin\n",
      "324 . jyotshikiritika\n",
      "325 . bakenetic\n",
      "326 . prabhps7\n",
      "327 . ashokkukreti5\n",
      "328 . linsk_itchen\n",
      "329 . kakukandi\n",
      "330 . sa.bakhan46\n",
      "331 . satshyaa\n",
      "332 . razzzdino\n",
      "333 . bhartilekhwani9139\n",
      "334 . rithilrajesh\n",
      "335 . chef_rahul_ponna\n",
      "336 . mr.cheapmunks\n",
      "337 . yashodhra_windlas\n",
      "338 . nowsayyum\n",
      "339 . architaag.chocolatier\n",
      "340 . prachibabla\n",
      "341 . rehanapathan1\n",
      "342 . madewithlove331\n",
      "343 . nilmanu\n",
      "344 . khurana7076\n",
      "345 . its_sumitdon_1432\n",
      "346 . lilpanda_17\n",
      "347 . pardeep_bishnoi_29029\n",
      "348 . aman.mittal7\n",
      "349 . swarna_pappa\n",
      "350 . jalajayagaya\n",
      "351 . kabijitdas\n",
      "352 . vvipchorabaadshah\n",
      "353 . appadam123\n",
      "354 . aparna_bagaria\n",
      "355 . sweetnsourstories\n",
      "356 . aakashyadav_2004\n",
      "357 . surbhi0984\n",
      "358 . chef.channel\n",
      "359 . paramveersinghhanspal\n",
      "360 . raksha.digital\n",
      "361 . rpawar420\n",
      "362 . rajairconditioner\n",
      "363 . milkywaychaser_\n",
      "364 . sanina14\n",
      "365 . _raiyan_0021_\n",
      "366 . kakkar_anmol\n",
      "367 . akshitas_food_blog\n",
      "368 . kalrananki\n",
      "369 . sonam.narang.779\n",
      "370 . swatichande05\n",
      "371 . my.own.world.15\n",
      "372 . sana.zafar.sz\n",
      "373 . brando_just_do\n",
      "374 . wandering_am\n",
      "375 . prajwal8321\n",
      "376 . md_arshu04\n",
      "377 . liza_richards\n",
      "378 . yummoments\n",
      "379 . foodyzone14\n",
      "380 . dear_food._\n",
      "381 . bhavika_budhdeo\n",
      "382 . vasanthi.b.5686\n",
      "383 . enlightenindia_magazine_pijpat\n",
      "384 . _sandeep0_\n",
      "385 . jugnusohi\n",
      "386 . nttsneh7893\n",
      "387 . pratibhachandra752018\n",
      "388 . madhumita8988\n",
      "389 . nawabs_royal_kitchen\n",
      "390 . kitchens_of_mumbai\n",
      "391 . dust_of_spices\n",
      "392 . lxkshx\n",
      "393 . furqan_shareef20\n",
      "394 . chris_jo._\n",
      "395 . 1927___fatima\n",
      "396 . magicdelight\n",
      "397 . advikrakhrai\n",
      "398 . _aman.ducd_\n",
      "399 . _charuuuu_.b\n",
      "400 . chicken_curry_and_a_king_bed\n",
      "401 . sharad427\n",
      "402 . ridhiibhatia\n",
      "403 . krushantgaikwad\n",
      "404 . bhatiadarpan\n",
      "405 . xx_c.o.o.l_b.o.y_\n",
      "406 . _mau_24\n",
      "407 . eatwithmini\n",
      "408 . chikuverma71\n",
      "409 . rshinde111\n",
      "410 . ybav43\n",
      "411 . ambrosia_burp\n",
      "412 . thecookingqueen.__\n",
      "413 . akib4274\n",
      "414 . foodsloverrrr\n",
      "415 . __ajmaj_khan__\n",
      "416 . local_billa\n",
      "417 . kitchenmintleaf\n",
      "418 . chottubhai846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419 . free_fire__khan_\n",
      "420 . javalkarshubham23\n",
      "421 . fashionart1817\n",
      "422 . _craving_hut_\n",
      "423 . brayan_polania1\n",
      "424 . brownieheaventelangana\n",
      "425 . neha0266\n",
      "426 . rukhsanaj311\n",
      "427 . dragon.chilly\n",
      "428 . kannu_b\n",
      "429 . inari.chennai\n",
      "430 . neha.pandey.5477\n",
      "431 . __anupa13__\n",
      "432 . mpihtts_\n",
      "433 . avaghadu\n",
      "434 . madhu.g.338\n",
      "435 . themumbaii\n",
      "436 . _ankit_mandal_\n",
      "437 . arjitaneja_forever\n",
      "438 . shrb_1210\n",
      "439 . dhi_man001\n",
      "440 . bhavesh_vaza_4794\n",
      "441 . vinaykumar_kamurthy\n",
      "442 . juann_e.l\n",
      "443 . _aslisona7\n",
      "444 . casper392945\n",
      "445 . nimisha12sharma\n",
      "446 . karthikkasid\n",
      "447 . evolution.works\n",
      "448 . __danish_zehen_fambruh_army\n",
      "449 . shoaibpathan72\n",
      "450 . bessan.lsmailk\n",
      "451 . _reet_55220\n",
      "452 . mr_craver\n",
      "453 . wanderer__rider\n",
      "454 . manjunathbj0411\n",
      "455 . sneh_shetty29\n",
      "456 . santiagoblair.ph\n",
      "457 . meenuagarwal69\n",
      "458 . i.am.akshatjain\n",
      "459 . food_blush\n",
      "460 . abhishek2708\n",
      "461 . _h_m.1_\n",
      "462 . itssharaannn\n",
      "463 . adt.browniewala\n",
      "464 . n31761507\n",
      "465 . kashi_vinapatel\n",
      "466 . pathetic.pictures\n",
      "467 . saurabh6830\n",
      "468 . _jayshree_72\n",
      "469 . harshmastakar\n",
      "470 . shailendra_gandhi\n",
      "471 . varunydv_\n",
      "472 . psy_instin\n",
      "473 . kriti.bathla\n",
      "474 . foodsupply._\n",
      "475 . thehomebakersdelhi\n",
      "476 . yogeshyadavrkt\n",
      "477 . _flying_2_high_\n",
      "478 . ghumakkad_rooh\n",
      "479 . heemuhn\n",
      "480 . nikhilthakrani\n",
      "481 . paras8871\n",
      "482 . raj___bubey__4u\n",
      "483 . lakshay_462\n",
      "484 . ankitales\n",
      "485 . akash.dangi.1276\n",
      "486 . moodychefdari\n",
      "487 . sonipallavi32\n",
      "488 . aachal.ahuja\n",
      "489 . katariamohit24\n",
      "490 . gharkahalwai\n",
      "491 . raudhi____king____sk\n",
      "492 . flavourfuel\n",
      "493 . renu_art_gallery3\n",
      "494 . ra4247448\n",
      "495 . momskitchen9059\n",
      "496 . cat_o_philliac\n",
      "497 . bake_n_roast_by_purans\n",
      "498 . deepak.me07\n",
      "499 . khushik450\n",
      "500 . praveen_bhagwani\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "driver.back()\n",
    "time.sleep(3)\n",
    "#clear search textBox and search for the profile name\n",
    "clear_search()\n",
    "profile_name='foodtalkindia'\n",
    "search(profile_name)\n",
    "\n",
    "#wait till the all data loads in the search dropdown then click on the first result\n",
    "wait=WebDriverWait(driver,10)\n",
    "profile=wait.until(EC.presence_of_element_located((By.XPATH,'//a[contains(@class,\"yCE8d  \")]')))\n",
    "profile.click()\n",
    "\n",
    "time.sleep(3)\n",
    "followers=driver.find_element_by_partial_link_text('followers')\n",
    "followers.click()\n",
    "\n",
    "#scroll down to expand the list\n",
    "results=driver.find_element_by_class_name('isgrP')\n",
    "\n",
    "for i in range(50):\n",
    "    time.sleep(1)\n",
    "    driver.execute_script(\"arguments[0].scrollTop=arguments[0].scrollHeight\",results)\n",
    "    \n",
    "followers_list=driver.find_elements_by_xpath(\"//a[contains(@class,'FPmhX ')]\")\n",
    "\n",
    "count=1\n",
    "for i in followers_list:\n",
    "    print(count,'.',i.get_attribute('innerHTML'))\n",
    "    count+=1\n",
    "    if count==501:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 2. Now print all the followers of “foodtalkindia” that you are following but those who don’t follow you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such users found\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "driver.back()\n",
    "time.sleep(3)\n",
    "#let we are on the page of 'foodtalkindia'\n",
    "followers=driver.find_element_by_partial_link_text('followers')\n",
    "followers.click()\n",
    "\n",
    "#scroll down to expand the list\n",
    "results=driver.find_element_by_class_name('isgrP')\n",
    "\n",
    "for i in range(30):\n",
    "    time.sleep(1)\n",
    "    driver.execute_script(\"arguments[0].scrollTop=arguments[0].scrollHeight\",results)\n",
    "    \n",
    "foodTalk_followers=driver.find_elements_by_xpath(\"//a[contains(@class,'FPmhX ')]\")\n",
    "\n",
    "s1=set()\n",
    "for i in foodTalk_followers:\n",
    "    s1.add(i.get_attribute('innerHTML'))\n",
    "\n",
    "driver.back()\n",
    "\n",
    "#clicking on user_profile image\n",
    "time.sleep(1)\n",
    "user_profile=driver.find_element_by_xpath('//span[contains(@class,\"qNELH\")]')\n",
    "user_profile.click()\n",
    "\n",
    "#entering to user profile section\n",
    "wait=WebDriverWait(driver,10)\n",
    "enter_profile=wait.until(EC.presence_of_element_located((By.XPATH,'//a[contains(@class,\"-qQT3\")]')))\n",
    "enter_profile.click()\n",
    "\n",
    "#clicking on followers to view followers\n",
    "userFollowing=driver.find_element_by_partial_link_text('following')\n",
    "userFollowing.click()\n",
    "\n",
    "result_list=driver.find_element_by_class_name('isgrP')\n",
    "\n",
    "for i in range(18):\n",
    "    time.sleep(1)\n",
    "    driver.execute_script(\"arguments[0].scrollTop=arguments[0].scrollHeight\",result_list)\n",
    "    \n",
    "user_following=driver.find_elements_by_xpath(\"//a[contains(@class,'FPmhX ')]\")\n",
    "\n",
    "s2=set()\n",
    "for i in user_following:\n",
    "    s2.add(i.get_attribute('innerHTML'))\n",
    "    \n",
    "driver.back()\n",
    "\n",
    "#finding common people from both set which are following 'foodtalkindia' and to whom user is following too.\n",
    "s1.intersection_update(s2)\n",
    "\n",
    "#now finding the list of user's followers\n",
    "userFollowers=driver.find_element_by_partial_link_text('followers')\n",
    "userFollowers.click()\n",
    "\n",
    "result_list2=driver.find_element_by_class_name('isgrP')\n",
    "\n",
    "for i in range(20):\n",
    "    time.sleep(1)\n",
    "    driver.execute_script(\"arguments[0].scrollTop=arguments[0].scrollHeight\",result_list2)\n",
    "\n",
    "user_followers=driver.find_elements_by_xpath(\"//a[contains(@class,'FPmhX ')]\")\n",
    "\n",
    "s3=set()\n",
    "for i in user_followers:\n",
    "    s3.add(i.get_attribute('innerHTML'))\n",
    "    \n",
    "driver.back()\n",
    "\n",
    "final_list=s1.difference(s3)\n",
    "\n",
    "#list of people who are following to 'foodtalkIndia' and to whom user is following but user is not followed back by them\n",
    "if len(final_list)==0:\n",
    "    print(\"No such users found\")\n",
    "else:\n",
    "    for i in final_list:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Check the story of ‘coding.ninjas’. Consider the following Scenarios and print error messages accordingly -\n",
    "            1. If You have already seen the story.\n",
    "            2. Or The user has no story.\n",
    "            3. Or View the story if not yet seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already seen the story\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "clear_search()\n",
    "profile_name= 'coding.ninjas'\n",
    "search(profile_name)\n",
    "\n",
    "wait=WebDriverWait(driver,10)\n",
    "profile=wait.until(EC.presence_of_element_located((By.XPATH,\"//a[contains(@class,'yCE8d')]\")))\n",
    "profile.click()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "try:\n",
    "    story=wait.until(EC.presence_of_element_located((By.CLASS_NAME,\"RR-M-.h5uC0\")))\n",
    "    \n",
    "    #check the dp size to find out story is available or not\n",
    "    height=driver.find_element_by_class_name('CfWVH').get_attribute('height')\n",
    "    if int(height)==166:\n",
    "        print(\"Already seen the story\")\n",
    "    else:\n",
    "        print(\"Viewing the story\")\n",
    "        driver.execute_script(\"arguments[0].click();\",story)\n",
    "except:\n",
    "    print(\"No story is available to view\")\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
